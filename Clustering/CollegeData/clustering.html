
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Question 5 : K-means Clustering</title><meta name="generator" content="MATLAB 9.1"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-08-15"><meta name="DC.source" content="clustering.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Question 5 : K-means Clustering</h1><!--introduction--><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#4">Question 6 : Hierarchical Clustering</a></li><li><a href="#11">7 b</a></li><li><a href="#12">7 c</a></li><li><a href="#13">7 d</a></li><li><a href="#14">7 e</a></li><li><a href="#15">7 f</a></li></ul></div><p><b>a. Choosing random centroids and plotting them</b></p><pre class="codeinput">data = [1 4 1;1 3 1;0 4 2;2 5 2;5 1 1;6 2 2;4 0 1;5 2 2];
x = data(:,1:2);

X1 = data(:,1);
X2 = data(:,2);
ig = data(:,3);
class_one = ig==1;
class_two = ig==2;
centInit(1,1) = sum(X1(class_one))/sum(class_one);
centInit(1,2) = sum(X2(class_one))/sum(class_one);
centInit(2,1) = sum(X1(class_two))/sum(class_two);
centInit(2,2) = sum(X2(class_two))/sum(class_two);

<span class="comment">% centInit = [5,1;1,0];</span>
disp(<span class="string">'The centroids are: '</span>)
disp(centInit)

plot(x(:,1), x(:,2), <span class="string">'ko'</span>)
hold <span class="string">on</span>;
plot(centInit(1,1), centInit(1,2), <span class="string">'ro'</span>, <span class="string">'MarkerFaceColor'</span>, <span class="string">'r'</span>, <span class="keyword">...</span>
    <span class="string">'MarkerSize'</span>, 8);
plot(centInit(2,1), centInit(2,2), <span class="string">'bo'</span>, <span class="string">'MarkerFaceColor'</span>, <span class="string">'b'</span>, <span class="keyword">...</span>
    <span class="string">'MarkerSize'</span>, 8);
xlabel(<span class="string">'x1'</span>);
ylabel(<span class="string">'x2'</span>);

xlim([min(min(data(1:end,1))-2,min(centInit(1:end,1))-2), max(max(data(1:end,1))+2,max(centInit(1:end,1))+2)])
ylim([min(min(data(1:end,2))-2,min(centInit(1:end,2))-2), max(max(data(1:end,2))+2,max(centInit(1:end,2))+2)])
</pre><pre class="codeoutput">The centroids are: 
    2.7500    2.0000
    3.2500    3.2500

</pre><img vspace="5" hspace="5" src="clustering_01.png" alt=""> <p><b>b. Assigning initial labels to the random centroids</b></p><pre class="codeinput">plotStyle = {<span class="string">'bo'</span>,<span class="string">'ro'</span>};

j = 1;
k = 1;
<span class="keyword">for</span> i = 1:size(data,1)
    <span class="keyword">if</span> data(i,end) == 1
        group1(j,:) = data(i,:);
        j = j + 1;
        plot(data(i,1),data(i,2),plotStyle{1})
        hold <span class="string">on</span>
    <span class="keyword">elseif</span> data(i,end) == 2
        group2(k,:) = data(i,:);
        k = k + 1;
        plot(data(i,1),data(i,2),plotStyle{2})
        hold <span class="string">on</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>
hold <span class="string">on</span>;
plot(centInit(1,1), centInit(1,2), <span class="string">'bo'</span>, <span class="string">'MarkerFaceColor'</span>, <span class="string">'b'</span>, <span class="keyword">...</span>
    <span class="string">'MarkerSize'</span>, 8);
plot(centInit(2,1), centInit(2,2), <span class="string">'ro'</span>, <span class="string">'MarkerFaceColor'</span>, <span class="string">'r'</span>, <span class="keyword">...</span>
        <span class="string">'MarkerSize'</span>, 8);
xlabel(<span class="string">'x1'</span>);
ylabel(<span class="string">'x2'</span>);
xlim([min(min(data(1:end,1))-2,min(centInit(1:end,1))-2), max(max(data(1:end,1))+2,max(centInit(1:end,1))+2)])
ylim([min(min(data(1:end,2))-2,min(centInit(1:end,2))-2), max(max(data(1:end,2))+2,max(centInit(1:end,2))+2)])

hold <span class="string">off</span>
</pre><img vspace="5" hspace="5" src="clustering_02.png" alt=""> <p><b>c. Assigning samples to new centroids, d. &amp; e.</b></p><pre class="codeinput">prev=0;

[A,B] = size(x);
iter=0;
err = zeros (1,100);
<span class="keyword">while</span> (iter &lt; 100)
    old_cent = centInit;
    <span class="comment">% Calculate distances of each point to the chosen centroids</span>
    d = pdist2(centInit,x, <span class="string">'euclidean'</span>);
    d = d.^2;
    <span class="comment">% Find the minimum distance centroid and assign the cluster label to each data sample</span>
    [data2,cluster_assignment]= min(d,[],1);
    iter = iter + 1;

    <span class="comment">% Calculate new centroids by taking a mean of all points in the existing cluster</span>
    <span class="keyword">for</span> i=1:2
         idx = find(cluster_assignment == i);
         centInit(i,:) = mean(x(idx,:),1);
    <span class="keyword">end</span>

    <span class="comment">% Calculating the sum of distances to the centres</span>
    error = sum(data2);
    <span class="comment">% Difference of previous SSE corresponding to previous centers to new SSE to new centers</span>
    sse = abs(prev-error);
    <span class="comment">% Stop clustering if SSE falls below 0.001</span>
    <span class="keyword">if</span>( sse &lt; 0.001)
        <span class="keyword">break</span>;
    <span class="comment">% Save the SSE to compare against new SSE</span>
    <span class="keyword">else</span>
        prev=error;
    <span class="keyword">end</span>
    <span class="comment">% Array of SSEs calculated per iteration</span>
    err(iter) = error;

    data(:,3) = cluster_assignment;
    j = 1;
    k = 1;
    <span class="keyword">for</span> i = 1:size(data,1)
        <span class="keyword">if</span> data(i,end) == 1
            group1(j,:) = data(i,:);
            j = j + 1;
            plot(data(i,1),data(i,2),plotStyle{1})
            hold <span class="string">on</span>
        <span class="keyword">elseif</span> data(i,end) == 2
            group2(k,:) = data(i,:);
            k = k + 1;
            plot(data(i,1),data(i,2),plotStyle{2})
            hold <span class="string">on</span>
        <span class="keyword">end</span>
    <span class="keyword">end</span>
    hold <span class="string">on</span>;
    plot(old_cent(1,1), old_cent(1,2), <span class="string">'bo'</span>, <span class="string">'MarkerFaceColor'</span>, <span class="string">'b'</span>, <span class="keyword">...</span>
        <span class="string">'MarkerSize'</span>, 8);
    plot(old_cent(2,1), old_cent(2,2), <span class="string">'ro'</span>, <span class="string">'MarkerFaceColor'</span>, <span class="string">'r'</span>, <span class="keyword">...</span>
        <span class="string">'MarkerSize'</span>, 8);
    xlabel(<span class="string">'x1'</span>);
    ylabel(<span class="string">'x2'</span>);
    xlim([min(min(data(1:end,1))-2,min(old_cent(1:end,1))-2), max(max(data(1:end,1))+2,max(old_cent(1:end,1))+2)])
    ylim([min(min(data(1:end,2))-2,min(old_cent(1:end,2))-2), max(max(data(1:end,2))+2,max(old_cent(1:end,2))+2)])

    title(sprintf(<span class="string">'Iteration %d'</span>, iter));
    snapnow;
    hold <span class="string">off</span>;
    disp(<span class="string">'The new centroid is: '</span>)
    disp(centInit)
<span class="keyword">end</span>

disp(<span class="string">'The centroids did not change, proving their stability'</span>)
</pre><img vspace="5" hspace="5" src="clustering_03.png" alt=""> <pre class="codeoutput">The new centroid is: 
    3.3333    1.3333
    2.8000    3.4000

</pre><img vspace="5" hspace="5" src="clustering_04.png" alt=""> <pre class="codeoutput">The new centroid is: 
    5.0000    1.2500
    1.0000    4.0000

</pre><img vspace="5" hspace="5" src="clustering_05.png" alt=""> <pre class="codeoutput">The new centroid is: 
    5.0000    1.2500
    1.0000    4.0000

The centroids did not change, proving their stability
</pre><h2 id="4">Question 6 : Hierarchical Clustering</h2><p><b>a. Complete linkage hierarchical clustering</b></p><pre class="codeinput">D = [0 0.3 0.4 0.7 0.6; 0.3 0 0.5 0.8 0.2; 0.4 0.5 0 0.45 0.4; 0.7 0.8 0.45 0 0.35; 0.6 0.2 0.4 0.35 0];
disp(<span class="string">'Given dissimilarity matrix: '</span>)
disp(D)
D_cell{1} = D;
old_D = D;
[r,c] = size(D);
p = 1;
<span class="keyword">while</span> r &gt; 2
    minimum = D(2,1); <span class="comment">% minimum other than 0; in other words, second minimum.</span>
    idx_r = 2;
    idx_c = 1;
    <span class="keyword">for</span> i = 2:r
        <span class="keyword">for</span> j = 1:(i-1)
            <span class="keyword">if</span> D(i,j) &lt;= minimum
                minimum = D(i,j);
                idx_r = i;
                idx_c = j;
            <span class="keyword">end</span>
        <span class="keyword">end</span>
    <span class="keyword">end</span>
    disp(<span class="string">'minimum distance in the matrix is: '</span>)
    disp(minimum)
    smallest(p) = minimum;

    <span class="comment">% Swap</span>
    <span class="comment">% This part swaps the second minimum in the row the minimum is found</span>
    <span class="comment">% and swaps with maximum value in that row. This preserves the second</span>
    <span class="comment">% minimum value of the matrix.</span>
    <span class="keyword">for</span> i = size(D,2)
        <span class="keyword">if</span> max(D(idx_c,:))==max(D(:))
            [a,b] = max(D(idx_c,:));
            A2 = sort(D(:,b));
            min_in_col = A2(2);
            min_in_col_pos = find(D(:,b)==min_in_col);
            D(min_in_col_pos,b) = a;
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    p = p + 1;

    <span class="keyword">for</span> i = 2:r
        <span class="keyword">for</span> j = 1:c
            D(i,j) = D(j,i);
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="comment">% Delete row and column:</span>
    <span class="comment">% This part deletes the row and the column in which the minimum value</span>
    <span class="comment">% is found.</span>
    D(idx_c,:) = [];
    D(:,idx_c) = [];
    [r,c]=size(D);
    disp(<span class="string">'Dissimilarity matrix after dimension reduction: '</span>)
    disp(D)
    D_cell{p} = D;
<span class="keyword">end</span>

<span class="keyword">if</span> r==2 &amp;&amp; c==2
    minimum = D(2,1);
<span class="keyword">end</span>

smallest(p) = minimum;
disp(<span class="string">'minimum distance in the matrix is: '</span>)
disp(minimum)
i = 1;
<span class="keyword">while</span> i &lt;= size(smallest,2)
    [a,b] = find(old_D==smallest(i));
    [c,~] = find(D_cell{i}==smallest(i));
    l1 = length(a)/2;
    l2 = length(c)/2;
    <span class="keyword">if</span> l1 &gt; 1 &amp;&amp; l2 &gt; 1
        j = 0;
        <span class="keyword">while</span> j &lt; l1
            rows(i) = a((j)*2+1);
            columns(i) = b((j)*2+1);
            j = j+1;
            i = i+1;
        <span class="keyword">end</span>
    <span class="keyword">else</span>
        <span class="keyword">if</span> i == 1
            rows(i) = a(end-1);
        <span class="keyword">else</span>
            rows(i) = rows(i-1)+1;
        <span class="keyword">end</span>
        columns(i) = b(end-1);
        i = i+1;
    <span class="keyword">end</span>
<span class="keyword">end</span>
rows = rows';
columns = columns';
heights = smallest';
Table_Q4 = table(rows, columns, heights);
disp(Table_Q4)
</pre><pre class="codeoutput">Given dissimilarity matrix: 
         0    0.3000    0.4000    0.7000    0.6000
    0.3000         0    0.5000    0.8000    0.2000
    0.4000    0.5000         0    0.4500    0.4000
    0.7000    0.8000    0.4500         0    0.3500
    0.6000    0.2000    0.4000    0.3500         0

minimum distance in the matrix is: 
    0.2000

Dissimilarity matrix after dimension reduction: 
         0    0.4000    0.7000    0.6000
    0.4000         0    0.4500    0.4000
    0.7000    0.4500         0    0.8000
    0.6000    0.4000    0.8000         0

minimum distance in the matrix is: 
    0.4000

Dissimilarity matrix after dimension reduction: 
         0    0.7000    0.6000
    0.7000         0    0.8000
    0.6000    0.8000         0

minimum distance in the matrix is: 
    0.6000

Dissimilarity matrix after dimension reduction: 
         0    0.8000
    0.8000         0

minimum distance in the matrix is: 
    0.8000

    rows    columns    heights
    ____    _______    _______

    5       2          0.2    
    3       1          0.4    
    5       3          0.6    
    6       2          0.8    

</pre><p><b>b. Single linkage hierarchical clustering</b></p><pre class="codeinput">clear
D = [0 0.3 0.4 0.7 0.6; 0.3 0 0.5 0.8 0.2; 0.4 0.5 0 0.45 0.4; 0.7 0.8 0.45 0 0.35; 0.6 0.2 0.4 0.35 0];
disp(<span class="string">'Given dissimilarity matrix: '</span>)
disp(D)
D_cell{1} = D;
old_D = D;
[r,c] = size(D);
p = 1;
<span class="keyword">while</span> r &gt; 2
    minimum = D(2,1); <span class="comment">% minimum other than 0; in other words, second minimum.</span>
    idx_r = 2;
    idx_c = 1;
    <span class="keyword">for</span> i = 2:r
        <span class="keyword">for</span> j = 1:(i-1)
            <span class="keyword">if</span> D(i,j) &lt; minimum
                minimum = D(i,j);
                idx_r = i;
                idx_c = j;
            <span class="keyword">end</span>
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    smallest(p) = minimum;
    disp(<span class="string">'minimum distance in the matrix is: '</span>)
    disp(minimum)

    <span class="comment">% Swap</span>
    <span class="comment">% This part swaps the second minimum in the row the minimum is found</span>
    <span class="comment">% and swaps with maximum value in that row. This preserves the second</span>
    <span class="comment">% minimum value of the matrix.</span>
    <span class="keyword">if</span> min(D(1,2:end))==D(1,idx_c)
        [~,b] = max(D(1,:));
        D(1,b) = D(1,idx_c);
        remember(p) = idx_c;
    <span class="keyword">else</span>
        remember(p) = 0;
    <span class="keyword">end</span>

    p = p + 1;

    <span class="keyword">for</span> i = 2:r
        <span class="keyword">for</span> j = 1:c
            D(i,j) = D(j,i);
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="comment">% Delete row and column</span>
    <span class="comment">% This part deletes the row and the column in which the minimum value</span>
    <span class="comment">% is found.</span>
    D(idx_c,:) = [];
    D(:,idx_c) = [];
    [r,c]=size(D);
    disp(<span class="string">'Dissimilarity matrix after dimension reduction: '</span>)
    disp(D)
    D_cell{p} = D;
<span class="keyword">end</span>

<span class="keyword">if</span> r==2 &amp;&amp; c==2
    minimum = D(2,1);
<span class="keyword">end</span>

smallest(p) = minimum;
disp(<span class="string">'minimum distance in the matrix is: '</span>)
disp(minimum)

i = 1;
<span class="keyword">while</span> i &lt;= size(smallest,2)
    [a,b] = find(old_D==smallest(i));
    [c,~] = find(D_cell{i}==smallest(i));
    l1 = length(a)/2;
    l2 = length(c)/2;
    <span class="keyword">if</span> l1 &gt; 1 &amp;&amp; l2 &gt; 1
        j = 0;
        <span class="keyword">while</span> j &lt; l1
            rows(i) = a((j)*2+1);
            columns(i) = b((j)*2+1);
            j = j+1;
            i = i+1;
        <span class="keyword">end</span>
    <span class="keyword">else</span>
        <span class="keyword">if</span> i == 1
            rows(i) = a(end-1);
        <span class="keyword">else</span>
            rows(i) = rows(i-1)+1;
        <span class="keyword">end</span>
        columns(i) = b(end-1);
        i = i+1;
    <span class="keyword">end</span>
<span class="keyword">end</span>

rows = rows';
columns = columns';
heights = smallest';
Table = table(rows, columns, heights);
disp(Table)
</pre><pre class="codeoutput">Given dissimilarity matrix: 
         0    0.3000    0.4000    0.7000    0.6000
    0.3000         0    0.5000    0.8000    0.2000
    0.4000    0.5000         0    0.4500    0.4000
    0.7000    0.8000    0.4500         0    0.3500
    0.6000    0.2000    0.4000    0.3500         0

minimum distance in the matrix is: 
    0.2000

Dissimilarity matrix after dimension reduction: 
         0    0.4000    0.3000    0.6000
    0.4000         0    0.4500    0.4000
    0.3000    0.4500         0    0.3500
    0.6000    0.4000    0.3500         0

minimum distance in the matrix is: 
    0.3000

Dissimilarity matrix after dimension reduction: 
         0    0.4500    0.4000
    0.4500         0    0.3500
    0.4000    0.3500         0

minimum distance in the matrix is: 
    0.3500

Dissimilarity matrix after dimension reduction: 
         0    0.4000
    0.4000         0

minimum distance in the matrix is: 
    0.4000

    rows    columns    heights
    ____    _______    _______

    5       2           0.2   
    6       1           0.3   
    7       4          0.35   
    8       3           0.4   

</pre><p><b>Dendrograms</b></p><pre class="codeinput">figure()
complete = imread(<span class="string">'complete.PNG'</span>);
imshow(complete);

figure()
single = imread(<span class="string">'single.PNG'</span>);
imshow(single);
</pre><img vspace="5" hspace="5" src="clustering_06.png" alt=""> <img vspace="5" hspace="5" src="clustering_07.png" alt=""> <p>Complete linkage: Samples (2,5), and (1,3) are in one cluster, the cluster formed by samples 2,5,1, and 3, i.e. ((2,5),(1,3)) form the second cluster, and the cluster formed by all the samples ((2,5),(1,3),((2,5),(1,3)), and 4) form the third cluster.</p><p>Single linkage: Samples (2,5), and 1 are in one cluster, the cluster formed by samples 2,5,1, and 3, i.e. ((2,5),1,4) form the second cluster, and the cluster formed by all the samples ((2,5),1,4,3) form the third cluster.</p><pre class="codeinput">fid = fopen(<span class="string">'college_data.csv'</span>,<span class="string">'r'</span>);
tline = fgets(fid);
variables = strsplit(tline, <span class="string">','</span>);
college_data = textscan(fid,<span class="string">'%d%s%s%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d'</span>,<span class="string">'delimiter'</span>,<span class="string">','</span>, <span class="string">'HeaderLines'</span>, 0);
fclose(fid);
<span class="comment">%</span>
numeric_college_data = [college_data{4:end}];
numeric_college_data = double(numeric_college_data);
trData = numeric_college_data;

<span class="comment">% minmax normalization</span>
<span class="keyword">for</span> i = 1:size(trData,2)
    trData_minmaxnorm(:,i) = (trData(:,i)-min(trData(:,i)))/(max(trData(:,i))-min(trData(:,i)));
<span class="keyword">end</span>
numeric_college_data = trData_minmaxnorm;

<span class="comment">% Zscore normalization</span>
<span class="comment">% for i = 1:size(trData,2)</span>
<span class="comment">%     trData_zscorenorm(:,i) = (trData(:,i)-mean(trData(:,i)))/std(trData(:,i));</span>
<span class="comment">% end</span>
<span class="comment">% numeric_college_data = trData_zscorenorm;</span>

<span class="comment">%</span>
Y = pdist(numeric_college_data);
Y = squareform(Y);
Z = linkage(Y, <span class="string">'complete'</span>);
figure()
[H,nodes,outperm] = dendrogram(Z);
set(gca,<span class="string">'Xtick'</span>,1:1:size(unique(college_data{1,3})))
set(gca, <span class="string">'XTickLabel'</span>, (college_data{1,3}(outperm))')
xtickangle(45)
title(<span class="string">'complete linkage for all colleges'</span>)
</pre><img vspace="5" hspace="5" src="clustering_08.png" alt=""> <h2 id="11">7 b</h2><pre class="codeinput">numeric_college_data_b = numeric_college_data;
college_data_b = college_data;

numeric_college_data_b((strcmp(<span class="string">'CSU-Chico'</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'CSU-Chico'</span>,college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp(<span class="string">'Columbia'</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'Columbia'</span>,college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp(<span class="string">'Northwestern'</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'Northwestern'</span>,college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp(<span class="string">'SFSU'</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'SFSU'</span>,college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp(<span class="string">'Berkeley'</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'Berkeley'</span>,college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp(<span class="string">'UCDavis'</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'UCDavis'</span>,college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp(<span class="string">'UCSB '</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'UCSB '</span>,college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp(<span class="string">'WPI'</span>,college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp(<span class="string">'WPI'</span>,college_data_b{1,3})),:) = [];

numeric_college_data_e = numeric_college_data_b;
college_data_e = college_data_b{1,3};
<span class="comment">%</span>
Y_b = pdist(numeric_college_data_b);
Y_b = squareform(Y_b);

<span class="comment">% complete</span>
Z_b_complete = linkage(Y_b, <span class="string">'complete'</span>);
figure()
[~,~,outperm_b] = dendrogram(Z_b_complete);
set(gca,<span class="string">'Xtick'</span>,1:1:size(unique(college_data_b{1,3})))
set(gca, <span class="string">'XTickLabel'</span>, (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title(<span class="string">'complete linkage for selected colleges'</span>)

<span class="comment">% average</span>
Z_b_average = linkage(Y_b, <span class="string">'average'</span>);
figure()
[~,~,outperm_b] = dendrogram(Z_b_average);
set(gca,<span class="string">'Xtick'</span>,1:1:size(unique(college_data_b{1,3}),1))
set(gca, <span class="string">'XTickLabel'</span>, (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title(<span class="string">'average linkage for selected colleges'</span>)
</pre><img vspace="5" hspace="5" src="clustering_09.png" alt=""> <img vspace="5" hspace="5" src="clustering_10.png" alt=""> <h2 id="12">7 c</h2><pre class="codeinput">Z_b_single = linkage(Y_b, <span class="string">'single'</span>);
figure()
[H_b,nodes_b,outperm_b] = dendrogram(Z_b_single);
set(gca,<span class="string">'Xtick'</span>,1:1:size(unique(college_data_b{1,3})))
set(gca, <span class="string">'XTickLabel'</span>, (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title(<span class="string">'single linkage for selected colleges'</span>)

<span class="comment">%</span>
lineage_matrix = Z_b_single;
k = 3;
clusters = cluster(lineage_matrix,<span class="string">'maxclust'</span>,k);
<span class="comment">% Find the distance threshold</span>
t = sort(lineage_matrix(:,3));
th = t(size(lineage_matrix,1)+2-k);
figure()
dendrogram(lineage_matrix,0,<span class="string">'colorthreshold'</span>, th);
set(gca,<span class="string">'Xtick'</span>,1:1:size(unique(college_data_b{1,3})))
set(gca, <span class="string">'XTickLabel'</span>, (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title(<span class="string">'single linkage for selected colleges with k = 3'</span>)
</pre><img vspace="5" hspace="5" src="clustering_11.png" alt=""> <img vspace="5" hspace="5" src="clustering_12.png" alt=""> <h2 id="13">7 d</h2><pre class="codeinput">[coeff,score,latent] = pca(numeric_college_data);
figure()
biplot(score(:,1:2),<span class="string">'varlabels'</span>,college_data{1,3});
xlabel(<span class="string">'1st principal component'</span>)
ylabel(<span class="string">'2nd principal component'</span>)
<span class="comment">% axis([-0.5 0.5 -0.5 0.6])</span>
<span class="comment">% figure()</span>
<span class="comment">% plot(score(:,1),score(:,2),'o');</span>
</pre><img vspace="5" hspace="5" src="clustering_13.png" alt=""> <h2 id="14">7 e</h2><pre class="codeinput">idx = kmeans(numeric_college_data_e,3);
<span class="comment">% disp(idx)</span>
cluster1 = college_data_e(idx==1);
cluster2 = college_data_e(idx==2);
cluster3 = college_data_e(idx==3);
disp(<span class="string">'Kmeans'</span>)
disp(cluster1)
disp(cluster2)
disp(cluster3)
</pre><pre class="codeoutput">Kmeans
    'CMU'
    'MIT'
    'NYU'
    'Stanford'

    'CSUEB'
    'CUNY'
    'MTU'
    'MSU '
    'SJSU'
    'UDel'

    'CalPoly'
    'UCSD'
    'UMinn '

</pre><h2 id="15">7 f</h2><pre class="codeinput">idx_medoids = kmedoids(numeric_college_data_e,3);
<span class="comment">% disp(idx_medoids)</span>
cluster1_medoids = college_data_e(idx_medoids==1);
cluster2_medoids = college_data_e(idx_medoids==2);
cluster3_medoids = college_data_e(idx_medoids==3);
disp(<span class="string">'Kmedoids'</span>)
disp(cluster1_medoids)
disp(cluster2_medoids)
disp(cluster3_medoids)
</pre><pre class="codeoutput">Kmedoids
    'CMU'
    'MIT'
    'Stanford'

    'CSUEB'
    'CUNY'
    'MTU'
    'MSU '
    'SJSU'

    'CalPoly'
    'NYU'
    'UCSD'
    'UDel'
    'UMinn '

</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2016b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Question 5 : K-means Clustering
%%
% *a. Choosing random centroids and plotting them*
data = [1 4 1;1 3 1;0 4 2;2 5 2;5 1 1;6 2 2;4 0 1;5 2 2];
x = data(:,1:2);

X1 = data(:,1);
X2 = data(:,2);
ig = data(:,3);
class_one = ig==1;
class_two = ig==2;
centInit(1,1) = sum(X1(class_one))/sum(class_one);
centInit(1,2) = sum(X2(class_one))/sum(class_one);
centInit(2,1) = sum(X1(class_two))/sum(class_two);
centInit(2,2) = sum(X2(class_two))/sum(class_two);

% centInit = [5,1;1,0];
disp('The centroids are: ')
disp(centInit)

plot(x(:,1), x(:,2), 'ko')
hold on;
plot(centInit(1,1), centInit(1,2), 'ro', 'MarkerFaceColor', 'r', ...
    'MarkerSize', 8);
plot(centInit(2,1), centInit(2,2), 'bo', 'MarkerFaceColor', 'b', ...
    'MarkerSize', 8);
xlabel('x1');
ylabel('x2');

xlim([min(min(data(1:end,1))-2,min(centInit(1:end,1))-2), max(max(data(1:end,1))+2,max(centInit(1:end,1))+2)])
ylim([min(min(data(1:end,2))-2,min(centInit(1:end,2))-2), max(max(data(1:end,2))+2,max(centInit(1:end,2))+2)])
%%
% *b. Assigning initial labels to the random centroids*
plotStyle = {'bo','ro'};

j = 1;
k = 1;
for i = 1:size(data,1)
    if data(i,end) == 1
        group1(j,:) = data(i,:);
        j = j + 1;
        plot(data(i,1),data(i,2),plotStyle{1})
        hold on
    elseif data(i,end) == 2
        group2(k,:) = data(i,:);
        k = k + 1;
        plot(data(i,1),data(i,2),plotStyle{2})
        hold on
    end
end
hold on;
plot(centInit(1,1), centInit(1,2), 'bo', 'MarkerFaceColor', 'b', ...
    'MarkerSize', 8);
plot(centInit(2,1), centInit(2,2), 'ro', 'MarkerFaceColor', 'r', ...
        'MarkerSize', 8);
xlabel('x1');
ylabel('x2');
xlim([min(min(data(1:end,1))-2,min(centInit(1:end,1))-2), max(max(data(1:end,1))+2,max(centInit(1:end,1))+2)])
ylim([min(min(data(1:end,2))-2,min(centInit(1:end,2))-2), max(max(data(1:end,2))+2,max(centInit(1:end,2))+2)])

hold off
%%
% *c. Assigning samples to new centroids, d. & e.*
prev=0;

[A,B] = size(x);
iter=0;
err = zeros (1,100);
while (iter < 100)
    old_cent = centInit;
    % Calculate distances of each point to the chosen centroids 
    d = pdist2(centInit,x, 'euclidean');
    d = d.^2;
    % Find the minimum distance centroid and assign the cluster label to each data sample
    [data2,cluster_assignment]= min(d,[],1);
    iter = iter + 1;
    
    % Calculate new centroids by taking a mean of all points in the existing cluster
    for i=1:2
         idx = find(cluster_assignment == i);
         centInit(i,:) = mean(x(idx,:),1);   
    end
    
    % Calculating the sum of distances to the centres
    error = sum(data2);
    % Difference of previous SSE corresponding to previous centers to new SSE to new centers
    sse = abs(prev-error);
    % Stop clustering if SSE falls below 0.001
    if( sse < 0.001)
        break;
    % Save the SSE to compare against new SSE
    else
        prev=error;
    end
    % Array of SSEs calculated per iteration
    err(iter) = error;
    
    data(:,3) = cluster_assignment;
    j = 1;
    k = 1;
    for i = 1:size(data,1)
        if data(i,end) == 1
            group1(j,:) = data(i,:);
            j = j + 1;
            plot(data(i,1),data(i,2),plotStyle{1})
            hold on
        elseif data(i,end) == 2
            group2(k,:) = data(i,:);
            k = k + 1;
            plot(data(i,1),data(i,2),plotStyle{2})
            hold on
        end
    end
    hold on;
    plot(old_cent(1,1), old_cent(1,2), 'bo', 'MarkerFaceColor', 'b', ...
        'MarkerSize', 8);
    plot(old_cent(2,1), old_cent(2,2), 'ro', 'MarkerFaceColor', 'r', ...
        'MarkerSize', 8);
    xlabel('x1');
    ylabel('x2');
    xlim([min(min(data(1:end,1))-2,min(old_cent(1:end,1))-2), max(max(data(1:end,1))+2,max(old_cent(1:end,1))+2)])
    ylim([min(min(data(1:end,2))-2,min(old_cent(1:end,2))-2), max(max(data(1:end,2))+2,max(old_cent(1:end,2))+2)])

    title(sprintf('Iteration %d', iter));
    snapnow;
    hold off;
    disp('The new centroid is: ')
    disp(centInit)
end

disp('The centroids did not change, proving their stability')
%% Question 6 : Hierarchical Clustering
%% 
% *a. Complete linkage hierarchical clustering*
D = [0 0.3 0.4 0.7 0.6; 0.3 0 0.5 0.8 0.2; 0.4 0.5 0 0.45 0.4; 0.7 0.8 0.45 0 0.35; 0.6 0.2 0.4 0.35 0];
disp('Given dissimilarity matrix: ')
disp(D)
D_cell{1} = D;
old_D = D;
[r,c] = size(D);
p = 1;
while r > 2
    minimum = D(2,1); % minimum other than 0; in other words, second minimum.
    idx_r = 2;
    idx_c = 1;
    for i = 2:r
        for j = 1:(i-1)
            if D(i,j) <= minimum
                minimum = D(i,j);
                idx_r = i;
                idx_c = j;
            end
        end
    end    
    disp('minimum distance in the matrix is: ')
    disp(minimum)
    smallest(p) = minimum;
    
    % Swap
    % This part swaps the second minimum in the row the minimum is found
    % and swaps with maximum value in that row. This preserves the second
    % minimum value of the matrix.
    for i = size(D,2)
        if max(D(idx_c,:))==max(D(:))
            [a,b] = max(D(idx_c,:));
            A2 = sort(D(:,b));
            min_in_col = A2(2);
            min_in_col_pos = find(D(:,b)==min_in_col);
            D(min_in_col_pos,b) = a;
        end
    end
    
    p = p + 1;
    
    for i = 2:r
        for j = 1:c
            D(i,j) = D(j,i);
        end
    end
    
    % Delete row and column:
    % This part deletes the row and the column in which the minimum value
    % is found.
    D(idx_c,:) = [];
    D(:,idx_c) = [];
    [r,c]=size(D);
    disp('Dissimilarity matrix after dimension reduction: ')
    disp(D)
    D_cell{p} = D;
end

if r==2 && c==2
    minimum = D(2,1);
end

smallest(p) = minimum;
disp('minimum distance in the matrix is: ')
disp(minimum)
i = 1;
while i <= size(smallest,2)
    [a,b] = find(old_D==smallest(i));
    [c,~] = find(D_cell{i}==smallest(i));
    l1 = length(a)/2;
    l2 = length(c)/2;
    if l1 > 1 && l2 > 1
        j = 0;
        while j < l1
            rows(i) = a((j)*2+1);
            columns(i) = b((j)*2+1);
            j = j+1;
            i = i+1;
        end
    else
        if i == 1
            rows(i) = a(end-1);
        else
            rows(i) = rows(i-1)+1;
        end
        columns(i) = b(end-1);
        i = i+1;
    end
end
rows = rows';
columns = columns';
heights = smallest';
Table_Q4 = table(rows, columns, heights);
disp(Table_Q4)
%%
% *b. Single linkage hierarchical clustering*
clear
D = [0 0.3 0.4 0.7 0.6; 0.3 0 0.5 0.8 0.2; 0.4 0.5 0 0.45 0.4; 0.7 0.8 0.45 0 0.35; 0.6 0.2 0.4 0.35 0];
disp('Given dissimilarity matrix: ')
disp(D)
D_cell{1} = D;
old_D = D;
[r,c] = size(D);
p = 1;
while r > 2
    minimum = D(2,1); % minimum other than 0; in other words, second minimum.
    idx_r = 2;
    idx_c = 1;
    for i = 2:r
        for j = 1:(i-1)
            if D(i,j) < minimum
                minimum = D(i,j);
                idx_r = i;
                idx_c = j;
            end
        end
    end    
    
    smallest(p) = minimum;
    disp('minimum distance in the matrix is: ')
    disp(minimum)
    
    % Swap
    % This part swaps the second minimum in the row the minimum is found
    % and swaps with maximum value in that row. This preserves the second
    % minimum value of the matrix.
    if min(D(1,2:end))==D(1,idx_c)
        [~,b] = max(D(1,:));
        D(1,b) = D(1,idx_c);
        remember(p) = idx_c;
    else
        remember(p) = 0;
    end
        
    p = p + 1;
    
    for i = 2:r
        for j = 1:c
            D(i,j) = D(j,i);
        end
    end
    
    % Delete row and column
    % This part deletes the row and the column in which the minimum value
    % is found.
    D(idx_c,:) = [];
    D(:,idx_c) = [];
    [r,c]=size(D);
    disp('Dissimilarity matrix after dimension reduction: ')
    disp(D)
    D_cell{p} = D;
end

if r==2 && c==2
    minimum = D(2,1);
end

smallest(p) = minimum;
disp('minimum distance in the matrix is: ')
disp(minimum)

i = 1;
while i <= size(smallest,2)
    [a,b] = find(old_D==smallest(i));
    [c,~] = find(D_cell{i}==smallest(i));
    l1 = length(a)/2;
    l2 = length(c)/2;
    if l1 > 1 && l2 > 1
        j = 0;
        while j < l1
            rows(i) = a((j)*2+1);
            columns(i) = b((j)*2+1);
            j = j+1;
            i = i+1;
        end
    else
        if i == 1
            rows(i) = a(end-1);
        else
            rows(i) = rows(i-1)+1;
        end
        columns(i) = b(end-1);
        i = i+1;
    end
end

rows = rows';
columns = columns';
heights = smallest';
Table = table(rows, columns, heights);
disp(Table)

%% 
% *Dendrograms*
figure()
complete = imread('complete.PNG');
imshow(complete);

figure()
single = imread('single.PNG');
imshow(single);
%%
% Complete linkage: Samples (2,5), and (1,3) are in one cluster, the
% cluster formed by samples 2,5,1, and 3, i.e. ((2,5),(1,3)) form the
% second cluster, and the cluster formed by all the samples
% ((2,5),(1,3),((2,5),(1,3)), and 4) form the third cluster.

%%
% Single linkage: Samples (2,5), and 1 are in one cluster, the
% cluster formed by samples 2,5,1, and 3, i.e. ((2,5),1,4) form the
% second cluster, and the cluster formed by all the samples
% ((2,5),1,4,3) form the third cluster.
%%
fid = fopen('college_data.csv','r');
tline = fgets(fid);
variables = strsplit(tline, ',');
college_data = textscan(fid,'%d%s%s%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d%d','delimiter',',', 'HeaderLines', 0);
fclose(fid);
%
numeric_college_data = [college_data{4:end}];
numeric_college_data = double(numeric_college_data);
trData = numeric_college_data;

% minmax normalization
for i = 1:size(trData,2)
    trData_minmaxnorm(:,i) = (trData(:,i)-min(trData(:,i)))/(max(trData(:,i))-min(trData(:,i)));
end
numeric_college_data = trData_minmaxnorm;

% Zscore normalization
% for i = 1:size(trData,2)
%     trData_zscorenorm(:,i) = (trData(:,i)-mean(trData(:,i)))/std(trData(:,i));
% end
% numeric_college_data = trData_zscorenorm;

%
Y = pdist(numeric_college_data);
Y = squareform(Y);
Z = linkage(Y, 'complete');
figure()
[H,nodes,outperm] = dendrogram(Z);
set(gca,'Xtick',1:1:size(unique(college_data{1,3})))
set(gca, 'XTickLabel', (college_data{1,3}(outperm))')
xtickangle(45)
title('complete linkage for all colleges')

%% 7 b
numeric_college_data_b = numeric_college_data;
college_data_b = college_data;

numeric_college_data_b((strcmp('CSU-Chico',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('CSU-Chico',college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp('Columbia',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('Columbia',college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp('Northwestern',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('Northwestern',college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp('SFSU',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('SFSU',college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp('Berkeley',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('Berkeley',college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp('UCDavis',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('UCDavis',college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp('UCSB ',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('UCSB ',college_data_b{1,3})),:) = [];

numeric_college_data_b((strcmp('WPI',college_data_b{1,3})),:)=[];
college_data_b{1,3}((strcmp('WPI',college_data_b{1,3})),:) = [];

numeric_college_data_e = numeric_college_data_b;
college_data_e = college_data_b{1,3};
%
Y_b = pdist(numeric_college_data_b);
Y_b = squareform(Y_b);

% complete
Z_b_complete = linkage(Y_b, 'complete');
figure()
[~,~,outperm_b] = dendrogram(Z_b_complete);
set(gca,'Xtick',1:1:size(unique(college_data_b{1,3})))
set(gca, 'XTickLabel', (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title('complete linkage for selected colleges')

% average
Z_b_average = linkage(Y_b, 'average');
figure()
[~,~,outperm_b] = dendrogram(Z_b_average);
set(gca,'Xtick',1:1:size(unique(college_data_b{1,3}),1))
set(gca, 'XTickLabel', (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title('average linkage for selected colleges')
%% 7 c
Z_b_single = linkage(Y_b, 'single');
figure()
[H_b,nodes_b,outperm_b] = dendrogram(Z_b_single);
set(gca,'Xtick',1:1:size(unique(college_data_b{1,3})))
set(gca, 'XTickLabel', (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title('single linkage for selected colleges')

%
lineage_matrix = Z_b_single;
k = 3;
clusters = cluster(lineage_matrix,'maxclust',k);
% Find the distance threshold
t = sort(lineage_matrix(:,3));
th = t(size(lineage_matrix,1)+2-k);
figure()
dendrogram(lineage_matrix,0,'colorthreshold', th);
set(gca,'Xtick',1:1:size(unique(college_data_b{1,3})))
set(gca, 'XTickLabel', (college_data_b{1,3}(outperm_b))')
xtickangle(45)
title('single linkage for selected colleges with k = 3')

%% 7 d
[coeff,score,latent] = pca(numeric_college_data);
figure()
biplot(score(:,1:2),'varlabels',college_data{1,3});
xlabel('1st principal component')
ylabel('2nd principal component')
% axis([-0.5 0.5 -0.5 0.6])
% figure()
% plot(score(:,1),score(:,2),'o');
%% 7 e
idx = kmeans(numeric_college_data_e,3);
% disp(idx)
cluster1 = college_data_e(idx==1);
cluster2 = college_data_e(idx==2);
cluster3 = college_data_e(idx==3);
disp('Kmeans')
disp(cluster1)
disp(cluster2)
disp(cluster3)
%% 7 f
idx_medoids = kmedoids(numeric_college_data_e,3);
% disp(idx_medoids)
cluster1_medoids = college_data_e(idx_medoids==1);
cluster2_medoids = college_data_e(idx_medoids==2);
cluster3_medoids = college_data_e(idx_medoids==3);
disp('Kmedoids')
disp(cluster1_medoids)
disp(cluster2_medoids)
disp(cluster3_medoids)
##### SOURCE END #####
--></body></html>